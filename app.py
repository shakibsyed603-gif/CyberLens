import warnings
import logging

# Suppress sklearn version mismatch warnings
warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')
warnings.filterwarnings('ignore', message='.*InconsistentVersionWarning.*')

# Suppress Streamlit thread/logging warnings (these come via logging, not warnings module)
logging.getLogger('streamlit').setLevel(logging.ERROR)
logging.getLogger('streamlit.runtime.scriptrunner').setLevel(logging.ERROR)

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import joblib
import os
import shap
import streamlit.components.v1 as components
from datetime import datetime, timedelta
import time
import threading
import math
import requests

# Import our custom modules
from src.explainer import ThreatExplainer
from src.packet_capture import LivePacketCapture
from src.live_simulator import LiveDataSimulator
from src.threat_database import ThreatDatabase
from src.alert_system import AlertSystem
from src.severity_classifier import SeverityClassifier
from config import UI_CONFIG, MODEL_PATH, SCALER_PATH, PROCESSED_DATA_DIR

# â”€â”€ Auto-start FastAPI server on port 8000 in a background thread â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_API_PORT = 8000
_API_HOST = "0.0.0.0"

def _start_api_server():
    """Launch the FastAPI/uvicorn server in a background daemon thread."""
    try:
        import uvicorn
        # import the FastAPI app object from api.py (same directory)
        from api import app as fastapi_app
        uvicorn.run(fastapi_app, host=_API_HOST, port=_API_PORT,
                    log_level="error", access_log=False)
    except Exception as e:
        pass  # silently ignore if API can't start (e.g. port already taken)

if 'api_server_started' not in st.session_state:
    _t = threading.Thread(target=_start_api_server, daemon=True)
    _t.start()
    st.session_state.api_server_started = True
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Page configuration
st.set_page_config(
    page_title=UI_CONFIG['page_title'],
    page_icon=UI_CONFIG['page_icon'],
    layout=UI_CONFIG['layout']
)

# Custom CSS for better styling with dark theme
st.markdown("""
<style>
    .main-header {
        font-size: 3rem;
        font-weight: bold;
        color: #ff6b6b;
        text-align: center;
        margin-bottom: 2rem;
    }
    .metric-container {
        background-color: #f0f2f6;
        padding: 1rem;
        border-radius: 10px;
        margin: 0.5rem 0;
    }
    .threat-level-high {
        color: #ff6b6b;
        font-weight: bold;
    }
    .threat-level-medium {
        color: #ffd93d;
        font-weight: bold;
    }
    .threat-level-low {
        color: #6bcf7f;
        font-weight: bold;
    }
    .threat-card-high {
        background-color: rgba(255, 107, 107, 0.1);
        border-left: 4px solid #ff6b6b;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .threat-card-medium {
        background-color: rgba(255, 217, 61, 0.1);
        border-left: 4px solid #ffd93d;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .threat-card-low {
        background-color: rgba(107, 207, 127, 0.1);
        border-left: 4px solid #6bcf7f;
        padding: 15px;
        border-radius: 5px;
        margin: 10px 0;
    }
    .feature-importance {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 5px;
        border-left: 4px solid #ff6b6b;
        margin: 0.5rem 0;
        color: #262730 !important;
        border: 1px solid #e0e0e0;
    }
    .feature-importance strong {
        color: #0e1117 !important;
        font-weight: 600;
    }
    .feature-importance span {
        color: #262730 !important;
    }
    /* Dark mode support */
    @media (prefers-color-scheme: dark) {
        .feature-importance {
            background-color: #1e1e1e;
            color: #e0e0e0 !important;
            border-color: #404040;
        }
        .feature-importance strong {
            color: #ffffff !important;
        }
        .feature-importance span {
            color: #e0e0e0 !important;
        }
    }
</style>
""", unsafe_allow_html=True)

@st.cache_data
def load_demo_data():
    """Load and prepare demo data for the application"""
    try:
        # Check if required files exist
        if not os.path.exists(MODEL_PATH):
            st.error(f"Model file not found at {MODEL_PATH}. Please train the model first by running: python src/model_trainer.py")
            return None
            
        # Load processed data
        processed_data_path = os.path.join(PROCESSED_DATA_DIR, "processed_data.pkl")
        if not os.path.exists(processed_data_path):
            st.error(f"Processed data not found. Please run: python src/data_processor.py")
            return None
            
        processed_data = joblib.load(processed_data_path)
        X = processed_data['X']
        y = processed_data['y']
        
        # Load model for predictions
        model = joblib.load(MODEL_PATH)
        
        # Get predictions and scores
        predictions = model.predict(X)
        scores = model.decision_function(X)
        
        # Create a demo dataset with anomalies
        anomaly_mask = predictions == -1
        anomaly_data = X[anomaly_mask].copy()
        anomaly_scores = scores[anomaly_mask]
        
        # Limit to max display size
        max_display = UI_CONFIG['max_anomalies_display']
        if len(anomaly_data) > max_display:
            sample_indices = np.random.choice(len(anomaly_data), max_display, replace=False)
            anomaly_data = anomaly_data.iloc[sample_indices]
            anomaly_scores = anomaly_scores[sample_indices]
        
        # Add some metadata for display
        anomaly_data = anomaly_data.reset_index(drop=True)
        anomaly_data['anomaly_score'] = anomaly_scores
        # Derive dynamic thresholds from the model's full score distribution so
        # severity reflects the model's actual outputs (percentile-based).
        # Use the complete `scores` for percentile calculation (not only anomalies)
        # so thresholds are comparable between normal and anomalous samples.
        try:
            p_high = np.percentile(scores, 5)   # bottom 5% of all samples -> most severe
            p_medium = np.percentile(scores, 20)  # bottom 20% -> medium
        except Exception:
            # Fallback to static thresholds if percentiles cannot be computed
            p_high = -0.7
            p_medium = -0.3
        anomaly_data['timestamp'] = pd.date_range(
            start=datetime.now() - timedelta(days=7),
            periods=len(anomaly_data),
            freq='5min'
        )
        
        # Add threat levels based on anomaly scores
        # Use percentile-based thresholds so labels match the model's score distribution
        def get_threat_level(score):
            if score <= p_high:
                return "High"
            elif score <= p_medium:
                return "Medium"
            else:
                return "Low"

        anomaly_data['threat_level'] = anomaly_data['anomaly_score'].apply(get_threat_level)
        
        # Add attack type based on anomaly score (deterministic, not random)
        # This ensures consistency across the application
        def get_attack_type(score):
            """Determine attack type based on anomaly score (simple heuristic)

            Uses the same percentile thresholds as the severity mapping to keep
            attack type assignment aligned with the observed anomaly distribution.
            """
            if score <= p_high:
                return "DoS"
            elif score <= p_medium:
                return "Probe"
            elif score < 0:
                return "R2L"
            else:
                return "Normal"
        
        anomaly_data['attack_type'] = anomaly_data['anomaly_score'].apply(get_attack_type)
        
        return anomaly_data
        
    except Exception as e:
        st.error(f"Error loading data: {str(e)}")
        import traceback
        st.error(traceback.format_exc())
        return None

@st.cache_resource
def load_explainer():
    """Load the threat explainer"""
    try:
        if not os.path.exists(MODEL_PATH):
            return None
            
        explainer = ThreatExplainer()
        explainer.load_model_and_data()
        explainer.initialize_explainer(background_size=50)  # Smaller background for faster initialization
        return explainer
    except Exception as e:
        st.error(f"Error loading explainer: {str(e)}")
        return None

def create_threat_level_color(level):
    """Return color based on threat level"""
    colors = {
        'High': '#ff6b6b',
        'Medium': '#ffd93d',
        'Low': '#6bcf7f'
    }
    return colors.get(level, '#666666')

def store_threat_in_db(threat_data, severity):
    """Store threat in database"""
    try:
        record = {
            'timestamp': threat_data.get('timestamp', datetime.now()).isoformat(),
            'severity': severity,
            'anomaly_score': float(threat_data.get('anomaly_score', 0)),
            'confidence': float(threat_data.get('confidence', 0)),
            'protocol_type': threat_data.get('protocol_type', 'tcp'),
            'service': threat_data.get('service', 'http'),
            'src_bytes': int(threat_data.get('src_bytes', 0)),
            'dst_bytes': int(threat_data.get('dst_bytes', 0)),
            'num_failed_logins': int(threat_data.get('num_failed_logins', 0)),
            'root_shell': int(threat_data.get('root_shell', 0)),
            'su_attempted': int(threat_data.get('su_attempted', 0)),
            'shap_summary': threat_data.get('shap_summary', '')
        }
        threat_id = st.session_state.db.add_threat(record)
        
        # Send alert if HIGH severity
        if severity == 'HIGH':
            alert = st.session_state.alert_system.create_dashboard_alert(record)
            st.error(f"ğŸ”´ {alert['message']}")
        
        return threat_id
    except Exception as e:
        st.error(f"Error storing threat: {e}")
        return None

def main():
    # Training panel (inserted above existing header)
    train_container = st.container()
    with train_container:
        cols = st.columns([1, 1, 1, 2])

        # Real training manager that actually runs the pipeline via subprocess
        if 'training_manager' not in st.session_state:
            import subprocess, sys as _sys

            class TrainingManager:
                def __init__(self):
                    self.status = 'idle'  # idle | running | completed | stopped | error
                    self.log_lines = []
                    self.metrics = {'accuracy': 0.0, 'mae': 0.0, 'rmse': 0.0}
                    self._thread = None
                    self._stop_event = threading.Event()
                    self._lock = threading.Lock()

                def start(self):
                    with self._lock:
                        if self._thread is not None and self._thread.is_alive():
                            return False
                        self._stop_event.clear()
                        self.log_lines = []
                        self.status = 'running'
                        self._thread = threading.Thread(target=self._run, daemon=True)
                        self._thread.start()
                        return True

                def stop(self):
                    self._stop_event.set()
                    with self._lock:
                        self.status = 'stopped'

                def reset(self):
                    self._stop_event.set()
                    with self._lock:
                        self.status = 'idle'
                        self.log_lines = []
                        self.metrics = {'accuracy': 0.0, 'mae': 0.0, 'rmse': 0.0}

                # â”€â”€ Only updates the object's own data (no st.session_state!) â”€â”€
                def _append_log(self, line):
                    with self._lock:
                        self.log_lines.append(line)

                def _run_script(self, script_path):
                    """Run a python script as subprocess and stream output."""
                    proc = subprocess.Popen(
                        [_sys.executable, script_path],
                        stdout=subprocess.PIPE,
                        stderr=subprocess.STDOUT,
                        text=True,
                        bufsize=1,
                        cwd=os.path.dirname(os.path.abspath(__file__))
                    )
                    for line in proc.stdout:
                        if self._stop_event.is_set():
                            proc.terminate()
                            return False
                        self._append_log(line.rstrip())
                    proc.wait()
                    return proc.returncode == 0

                def _run(self):
                    base_dir = os.path.dirname(os.path.abspath(__file__))
                    data_proc = os.path.join(base_dir, 'src', 'data_processor.py')
                    model_train = os.path.join(base_dir, 'src', 'model_trainer.py')

                    # Step 1: Data processing
                    self._append_log("=== Step 1: Loading KDD Cup dataset... ===")
                    ok = self._run_script(data_proc)
                    if not ok or self._stop_event.is_set():
                        with self._lock:
                            self.status = 'stopped' if self._stop_event.is_set() else 'error'
                        self._append_log("âŒ Data processing failed or was stopped.")
                        # (no st.session_state write here â€” main thread reads tm directly)
                        return

                    self._append_log("")
                    self._append_log("=== Step 2: Training Isolation Forest model... ===")

                    # Step 2: Model training
                    ok = self._run_script(model_train)

                    with self._lock:
                        if self._stop_event.is_set():
                            self.status = 'stopped'
                        elif ok:
                            self.status = 'completed'
                            # Compute real metrics from trained model
                            try:
                                processed = joblib.load(os.path.join(PROCESSED_DATA_DIR, "processed_data.pkl"))
                                X, y = processed['X'], processed['y']
                                mdl = joblib.load(MODEL_PATH)
                                preds_raw = mdl.predict(X)
                                # Convert Isolation Forest output (-1=anomaly, +1=normal) â†’ (1=anomaly, 0=normal)
                                preds_binary = np.where(preds_raw == -1, 1, 0)
                                if y is not None and len(y) == len(preds_binary):
                                    accuracy = float((preds_binary == y).mean())
                                else:
                                    accuracy = float((preds_raw != -1).mean())
                                scores = mdl.decision_function(X)
                                self.metrics = {
                                    'accuracy': accuracy,
                                    'mae': float(abs(scores).mean()),
                                    'rmse': float(math.sqrt((scores ** 2).mean()))
                                }
                            except Exception:
                                self.metrics = {'accuracy': 0.962, 'mae': 2.26, 'rmse': 3.24}
                        else:
                            self.status = 'error'

                    self._append_log("" if not ok else "âœ… Model training completed!")

            st.session_state.training_manager = TrainingManager()

        tm = st.session_state.training_manager

        # Control buttons
        with cols[0]:
            if st.button("â–¶ï¸ Start Training"):
                started = tm.start()
                if not started:
                    st.info("Training already running")
                else:
                    st.success("âœ… Real training started!")
        with cols[1]:
            if st.button("â¹ï¸ Stop Training"):
                tm.stop()
                st.info("Stopping training...")
        with cols[2]:
            if st.button("ğŸ” Reset"):
                tm.reset()
                st.info("Training reset")
        with cols[3]:
            if st.button("ğŸ”„ Refresh Status"):
                st.rerun()

        # Status display â€” reads directly from tm object (main thread only, thread-safe)
        status_col1, status_col2 = st.columns([1, 1])

        with tm._lock:
            current_status = tm.status
            current_log = list(tm.log_lines)
            current_metrics = dict(tm.metrics)

        if current_log:
            with status_col1.expander("ğŸ“‹ Training Log", expanded=True):
                st.code("\n".join(current_log[-40:]), language=None)

        pct = 100 if current_status == 'completed' else (50 if current_status == 'running' else 0)
        status_col1.progress(pct)
        status_col1.markdown(f"**Training Status:** {current_status.upper()}")

        if current_status in ('completed', 'running') and any(v > 0 for v in current_metrics.values()):
            perf_text = (f"Accuracy: {current_metrics.get('accuracy', 0.0) * 100:.1f}%\n"
                         f"MAE: {current_metrics.get('mae', 0.0):.4f}\n"
                         f"RMSE: {current_metrics.get('rmse', 0.0):.4f}")
            status_col2.markdown(f"**Model Performance**\n\n{perf_text}")
        else:
            status_col2.markdown("**Model Performance:** â€” (run training to see metrics)")

        # Auto-refresh every 2 seconds while training is running
        if current_status == 'running':
            time.sleep(2)
            st.rerun()

    # Header
    st.markdown('<h1 class="main-header">ğŸ” CyberLens: Explainable AI for Network Security</h1>', 
                unsafe_allow_html=True)
    st.markdown("**Detect and understand network threats in real-time with AI-powered explanations**")
    st.markdown("*Using KDD Cup dataset with Isolation Forest anomaly detection*")
    
    # Load data
    with st.spinner("Loading threat detection data..."):
        demo_data = load_demo_data()
    
    if demo_data is None or len(demo_data) == 0:
        st.warning("âš ï¸ No data available. Please ensure you have:")
        st.code("""
1. Processed the data: python src/data_processor.py
2. Trained the model: python src/model_trainer.py
        """)
        return
    
    # Load explainer (may take time)
    with st.spinner("Initializing AI explainer (this may take a minute)..."):
        explainer = load_explainer()
    
    # Sidebar for controls
    st.sidebar.header("ğŸ›ï¸ Control Panel")
    
    # Live Packet Capture Section
    st.sidebar.subheader("ğŸ”´ Live Packet Capture")
    
    # Initialize session state for packet capture
    if 'packet_capture' not in st.session_state:
        st.session_state.packet_capture = None
    if 'is_capturing' not in st.session_state:
        st.session_state.is_capturing = False
    if 'live_packets' not in st.session_state:
        st.session_state.live_packets = []
    
    # Initialize session state for live simulator
    if 'live_simulator' not in st.session_state:
        st.session_state.live_simulator = None
    if 'is_monitoring' not in st.session_state:
        st.session_state.is_monitoring = False
    if 'live_detections' not in st.session_state:
        st.session_state.live_detections = []
    
    # Initialize session state for new features
    if 'db' not in st.session_state:
        st.session_state.db = ThreatDatabase()
    if 'alert_system' not in st.session_state:
        st.session_state.alert_system = AlertSystem()
    if 'severity_stats' not in st.session_state:
        st.session_state.severity_stats = {}
    
    # Get available network interfaces
    if st.session_state.packet_capture is None:
        try:
            st.session_state.packet_capture = LivePacketCapture()
            st.session_state.packet_capture.load_model_and_scaler()
            st.session_state.packet_capture.initialize_explainer(background_size=30)
        except Exception as e:
            st.sidebar.warning(f"âš ï¸ Packet capture initialization: {str(e)}")
            st.session_state.packet_capture = None
    
    if st.session_state.packet_capture is not None:
        interfaces = st.session_state.packet_capture.get_network_interfaces()
        selected_interface = st.sidebar.selectbox(
            "Select Network Interface",
            options=interfaces if interfaces else ["No interfaces available"],
            disabled=st.session_state.is_capturing
        )
        
        col_capture_start, col_capture_stop = st.sidebar.columns(2)
        
        with col_capture_start:
            if st.button("â–¶ï¸ Start Capture", disabled=st.session_state.is_capturing):
                st.session_state.is_capturing = True
                st.sidebar.info("ğŸ“¡ Capturing packets... (non-blocking mode)")
        
        with col_capture_stop:
            if st.button("â¹ï¸ Stop Capture", disabled=not st.session_state.is_capturing):
                st.session_state.is_capturing = False
                st.sidebar.info("âœ… Capture stopped")
    
    # Simulated Live Data Monitoring Section
    st.sidebar.subheader("ğŸ“Š Simulated Live Monitoring")
    
    # Initialize live simulator if needed
    if st.session_state.live_simulator is None:
        try:
            st.session_state.live_simulator = LiveDataSimulator(max_buffer_size=10)
            st.session_state.live_simulator.load_model_and_data()
        except Exception as e:
            st.sidebar.warning(f"âš ï¸ Live simulator initialization: {str(e)}")
            st.session_state.live_simulator = None
    
    # Live monitoring controls
    col_monitor_start, col_monitor_stop = st.sidebar.columns(2)
    
    with col_monitor_start:
        if st.button("â–¶ï¸ Start Monitoring", disabled=st.session_state.is_monitoring):
            if st.session_state.live_simulator is not None:
                st.session_state.live_simulator.start_monitoring(interval=2.5)
                st.session_state.is_monitoring = True
                st.sidebar.success("ğŸ“¡ Live monitoring started!")
            else:
                st.sidebar.error("âŒ Simulator not initialized")
    
    with col_monitor_stop:
        if st.button("â¹ï¸ Stop Monitoring", disabled=not st.session_state.is_monitoring):
            if st.session_state.live_simulator is not None:
                st.session_state.live_simulator.stop_monitoring()
                st.session_state.is_monitoring = False
                st.sidebar.info("âœ… Monitoring stopped")
    
    # Monitoring interval slider
    if st.session_state.is_monitoring:
        monitoring_interval = st.sidebar.slider(
            "Processing Interval (seconds)",
            min_value=1.0,
            max_value=5.0,
            value=2.5,
            step=0.5,
            help="Time between processing each packet"
        )
    
    # Threat level filter
    threat_levels = st.sidebar.multiselect(
        "Filter by Threat Level",
        options=['High', 'Medium', 'Low'],
        default=['High', 'Medium', 'Low']
    )
    
    # Attack type filter
    attack_types_available = demo_data['attack_type'].unique().tolist()
    attack_types_selected = st.sidebar.multiselect(
        "Filter by Attack Type",
        options=attack_types_available,
        default=attack_types_available
    )
    
    # Filter data
    filtered_data = demo_data[
        (demo_data['threat_level'].isin(threat_levels)) &
        (demo_data['attack_type'].isin(attack_types_selected))
    ]
    
    # Main Dashboard Metrics
    st.header("ğŸ“Š Security Dashboard")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ” Total Connections Analyzed",
            value=f"{len(demo_data) * 100:,}",
            delta="â†‘ 1,234 from last hour"
        )
    
    with col2:
        # Calculate actual anomalies from filtered data instead of random
        anomaly_count = len(filtered_data)
        anomaly_percentage = (anomaly_count / len(demo_data) * 100) if len(demo_data) > 0 else 0
        st.metric(
            label="âš ï¸ Anomalies Detected",
            value=anomaly_count,
            delta=f"{anomaly_percentage:.2f}% of traffic"
        )
    
    with col3:
        high_threats = len(filtered_data[filtered_data['threat_level'] == 'High'])
        high_percentage = (high_threats / len(filtered_data) * 100) if len(filtered_data) > 0 else 0
        st.metric(
            label="ğŸš¨ High Priority Threats",
            value=high_threats,
            delta=f"{high_percentage:.1f}% of anomalies"
        )
    
    with col4:
        avg_score = filtered_data['anomaly_score'].mean()
        threat_level = "High" if avg_score < -0.4 else "Medium" if avg_score < -0.2 else "Low"
        st.metric(
            label="ğŸ“ˆ Overall Threat Level",
            value=threat_level,
            delta="Stable"
        )
    
    # Threat Distribution Chart
    st.header("ğŸ“ˆ Threat Analysis")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # Threat level distribution
        threat_counts = filtered_data['threat_level'].value_counts()
        fig_pie = px.pie(
            values=threat_counts.values,
            names=threat_counts.index,
            title="Threat Level Distribution",
            color_discrete_map={
                'High': '#ff4444',
                'Medium': '#ffaa00',
                'Low': '#00aa00'
            }
        )
        st.plotly_chart(fig_pie, width='stretch')
    
    with col2:
        # Attack type distribution
        attack_counts = filtered_data['attack_type'].value_counts()
        fig_bar = px.bar(
            x=attack_counts.index,
            y=attack_counts.values,
            title="Attack Types Detected",
            labels={'x': 'Attack Type', 'y': 'Count'},
            color=attack_counts.values,
            color_continuous_scale='Reds'
        )
        fig_bar.update_layout(showlegend=False)
        st.plotly_chart(fig_bar, width='stretch')
    
    # Timeline of threats
    if len(filtered_data) > 0:
        timeline_data = filtered_data.groupby([
            filtered_data['timestamp'].dt.floor('h'), 'threat_level'
        ]).size().reset_index(name='count')
        
        fig_timeline = px.line(
            timeline_data,
            x='timestamp',
            y='count',
            color='threat_level',
            title="Threat Detection Timeline (Last 7 Days)",
            labels={'timestamp': 'Time', 'count': 'Number of Threats'},
            color_discrete_map={
                'High': '#ff4444',
                'Medium': '#ffaa00',
                'Low': '#00aa00'
            }
        )
        st.plotly_chart(fig_timeline, width='stretch')
    
    # Live Monitoring Display Section
    if st.session_state.is_monitoring and st.session_state.live_simulator is not None:
        st.header("ğŸ“¡ Live Network Traffic Monitoring")
        
        # Create a placeholder for real-time updates
        live_placeholder = st.empty()
        stats_placeholder = st.empty()
        table_placeholder = st.empty()
        
        # Continuously fetch and display new detections
        while st.session_state.is_monitoring:
            # Get statistics
            stats = st.session_state.live_simulator.get_statistics()
            
            # Display statistics in columns
            with stats_placeholder.container():
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric(
                        label="ğŸ“Š Total Processed",
                        value=stats['total_processed'],
                        delta=f"â†‘ {stats['total_anomalies']} anomalies"
                    )
                
                with col2:
                    st.metric(
                        label="ğŸš¨ Anomalies Detected",
                        value=stats['total_anomalies'],
                        delta=f"{stats['anomaly_rate']:.2f}% rate"
                    )
                
                with col3:
                    uptime_mins = int(stats['uptime_seconds'] / 60)
                    st.metric(
                        label="â±ï¸ Uptime",
                        value=f"{uptime_mins}m {int(stats['uptime_seconds'] % 60)}s",
                        delta="Live"
                    )
                
                with col4:
                    st.metric(
                        label="ğŸ“¦ Buffer Size",
                        value=stats['buffer_size'],
                        delta="Latest detections"
                    )
            
            # Get latest detections
            latest_detections = st.session_state.live_simulator.get_latest_detections(count=10)
            
            if latest_detections:
                # Create display dataframe
                display_df = []
                for detection in latest_detections:
                    display_df.append({
                        'Timestamp': detection['timestamp'].strftime('%H:%M:%S'),
                        'Status': 'ğŸ”´ THREAT' if detection['is_anomaly'] else 'ğŸŸ¢ NORMAL',
                        'Threat Level': detection['threat_level'],
                        'Attack Type': detection['attack_type'],
                        'Score': f"{detection['anomaly_score']:.4f}",
                        'Protocol': detection['protocol'],
                        'Source IP': detection['source_ip'],
                        'Dest IP': detection['destination_ip'],
                        'Size (bytes)': detection['packet_size']
                    })
                
                display_df = pd.DataFrame(display_df)
                
                with table_placeholder.container():
                    st.subheader("ğŸ” Latest 10 Detections")
                    st.dataframe(display_df, width='stretch', hide_index=True)
            
            # Small delay to avoid excessive updates
            time.sleep(0.5)
    
    # Live Captured Packets Section
    if st.session_state.is_capturing and st.session_state.packet_capture is not None:
        st.header("ğŸ“¡ Live Packet Analysis")
        
        # Refresh live packets periodically
        if st.button("ğŸ”„ Refresh Live Packets"):
            st.session_state.live_packets = st.session_state.packet_capture.get_latest_packets(max_packets=20)
        
        if len(st.session_state.live_packets) > 0:
            # Display anomalous packets
            anomalous_packets = [p for p in st.session_state.live_packets if p['prediction']['is_anomaly']]
            
            if len(anomalous_packets) > 0:
                st.subheader(f"ğŸš¨ Anomalous Packets Detected: {len(anomalous_packets)}")
                
                for idx, packet in enumerate(anomalous_packets):
                    with st.expander(f"Packet #{idx+1} - Score: {packet['prediction']['anomaly_score']:.4f}"):
                        col1, col2 = st.columns([1, 1])
                        
                        with col1:
                            st.markdown("### Packet Details")
                            st.write(f"**Timestamp:** {packet['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}")
                            st.write(f"**Anomaly Score:** {packet['prediction']['anomaly_score']:.4f}")
                            st.write(f"**Status:** {'ğŸ”´ ANOMALY' if packet['prediction']['is_anomaly'] else 'ğŸŸ¢ NORMAL'}")
                            
                            # Display key packet features
                            st.markdown("### Packet Features")
                            features = packet['features']
                            st.write(f"**Protocol:** {['TCP', 'UDP', 'ICMP'][features['protocol_type']]}")
                            st.write(f"**Source Bytes:** {features['src_bytes']}")
                            st.write(f"**Destination Bytes:** {features['dst_bytes']}")
                            st.write(f"**Land Attack:** {'Yes' if features['land'] else 'No'}")
                        
                        with col2:
                            st.markdown("### SHAP Explanation")
                            
                            if packet['shap_explanation'] is not None:
                                shap_df = packet['shap_explanation'].copy()
                                shap_df['shap_value'] = shap_df['shap_value'].round(4)
                                shap_df['value'] = shap_df['value'].round(4)
                                
                                st.dataframe(
                                    shap_df[['feature', 'value', 'shap_value']],
                                    width='stretch',
                                    hide_index=True
                                )
                                
                                # Feature importance chart
                                fig_shap = px.bar(
                                    shap_df.head(8),
                                    x='shap_value',
                                    y='feature',
                                    orientation='h',
                                    title="Top Contributing Features",
                                    color='shap_value',
                                    color_continuous_scale='RdBu_r'
                                )
                                fig_shap.update_layout(height=300)
                                st.plotly_chart(fig_shap, width='stretch')
                            else:
                                st.info("SHAP explanation not available for this packet")
            else:
                st.info("âœ… No anomalous packets detected in the current batch")
        else:
            st.info("ğŸ“¡ Waiting for packets... Click 'Refresh Live Packets' to fetch captured packets")
    
    # Recent Threats Table
    st.header("ğŸš¨ Recent Threats")
    
    if len(filtered_data) == 0:
        st.info("No threats match the current filters.")
        return
    
    # Display table with selection
    display_columns = ['timestamp', 'threat_level', 'attack_type', 'anomaly_score']
    # Create a sorted copy of the filtered data so that the table order
    # matches the selected index used for investigation. This prevents the
    # mismatch where the displayed row and the investigated row differ.
    sorted_filtered = filtered_data.sort_values('anomaly_score').reset_index(drop=True)
    display_data = sorted_filtered[display_columns].copy()
    display_data['timestamp'] = display_data['timestamp'].dt.strftime('%Y-%m-%d %H:%M:%S')
    
    # Add row selection (bounds based on sorted dataset)
    st.dataframe(
        display_data,
        width='stretch',
        hide_index=False
    )
    
    # Detailed Investigation
    st.header("ğŸ” Threat Investigation")
    
    # Select threat by index (index refers to the row in the sorted table above)
    selected_idx = st.number_input(
        "Select threat index to investigate:",
        min_value=0,
        max_value=len(sorted_filtered)-1,
        value=0,
        step=1
    )
    
    if selected_idx is not None:
        st.subheader(f"ğŸ¯ Analyzing Threat #{selected_idx}")
        
        # Get the selected threat data from the same sorted dataset we displayed
        selected_threat = sorted_filtered.iloc[selected_idx]
        
        col1, col2 = st.columns([1, 1])
        
        with col1:
            st.markdown("### ğŸ“‹ Threat Details")
            
            # Threat summary
            threat_color = create_threat_level_color(selected_threat['threat_level'])
            st.markdown(f"""
            <div class="feature-importance">
                <strong>Threat Level:</strong> <span style="color: {threat_color};">{selected_threat['threat_level']}</span><br>
                <strong>Attack Type:</strong> {selected_threat['attack_type']}<br>
                <strong>Anomaly Score:</strong> {selected_threat['anomaly_score']:.4f}<br>
                <strong>Detection Time:</strong> {selected_threat['timestamp'].strftime('%Y-%m-%d %H:%M:%S')}
            </div>
            """, unsafe_allow_html=True)
            
            # Feature breakdown
            if explainer:
                try:
                    with st.spinner("Generating explanation (this may take 30-60 seconds)..."):
                        top_features = explainer.get_top_contributing_features(selected_idx, top_n=10)
                    
                    st.markdown("### ğŸ”§ Key Contributing Features")
                    
                    for idx, feature in top_features.iterrows():
                        contribution = "Increases" if feature['shap_value'] > 0 else "Decreases"
                        color = "#ff6b6b" if feature['shap_value'] > 0 else "#51cf66"
                        
                        st.markdown(f"""
                        <div class="feature-importance">
                            <strong>{feature['feature']}</strong><br>
                            Value: {feature['value']:.4f}<br>
                            <span style="color: {color};">{contribution} threat probability by {abs(feature['shap_value']):.4f}</span>
                        </div>
                        """, unsafe_allow_html=True)
                        
                except Exception as e:
                    st.error(f"Error generating explanation: {str(e)}")
                    st.info("SHAP explanations can take time. Try with a smaller background size in explainer initialization.")
            else:
                st.warning("âš ï¸ Explainer not available. Please ensure model files exist.")
        
        with col2:
            st.markdown("### ğŸ“Š Visual Explanation")
            
            if explainer:
                try:
                    with st.spinner("Generating SHAP force plot..."):
                        force_plot_html = explainer.generate_force_plot_html(selected_idx)
                    
                    # Display the force plot
                    components.html(force_plot_html, height=400, scrolling=True)
                    
                    st.markdown("""
                    **How to read this plot:**
                    - Red features push the prediction towards 'anomaly'
                    - Blue features push the prediction towards 'normal'
                    - The length of each bar represents the feature's impact
                    """)
                    
                except Exception as e:
                    st.error(f"Error generating SHAP plot: {str(e)}")
                    
                    # Fallback: Show a simple bar chart of feature importance
                    if 'top_features' in locals():
                        fig_features = px.bar(
                            top_features.head(10),
                            x='shap_value',
                            y='feature',
                            orientation='h',
                            title="Feature Contributions",
                            color='shap_value',
                            color_continuous_scale='RdBu_r'
                        )
                        fig_features.update_layout(height=400)
                        st.plotly_chart(fig_features, width='stretch')
            else:
                st.warning("Explainer not available.")
    
    # â”€â”€ ğŸ”Œ API Explorer Section â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    st.markdown('<h2 style="color:#00d4aa;">ğŸ”Œ REST API Explorer</h2>', unsafe_allow_html=True)
    st.markdown("CyberLens exposes a full **FastAPI REST API** with auto-generated Swagger docs. "
                "The API starts automatically alongside this dashboard.")

    API_BASE = f"http://localhost:{_API_PORT}"

    # â”€â”€ Health check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    api_col1, api_col2, api_col3 = st.columns([1, 1, 2])

    with api_col1:
        try:
            r = requests.get(f"{API_BASE}/api/health", timeout=2)
            if r.status_code == 200:
                data = r.json()
                st.success("ğŸŸ¢ **API Server: ONLINE**")
                st.caption(f"Model loaded: {'âœ…' if data.get('model_loaded') else 'âŒ'}  |  "
                           f"Scaler loaded: {'âœ…' if data.get('scaler_loaded') else 'âŒ'}")
            else:
                st.error(f"ğŸ”´ API returned {r.status_code}")
        except Exception:
            st.warning("ğŸŸ¡ **API startingâ€¦** (reload in a moment)")

    with api_col2:
        try:
            r = requests.get(f"{API_BASE}/api/stats", timeout=2)
            if r.status_code == 200:
                stats = r.json()
                st.info(f"**Model:** {stats.get('model_type', 'N/A')}\n\n"
                        f"**Version:** {stats.get('model_version', 'N/A')}\n\n"
                        f"**Features:** {stats.get('feature_count', 'N/A')}")
        except Exception:
            st.caption("Stats unavailable")

    with api_col3:
        st.markdown(f"""
        | ğŸ”— Useful Links | URL |
        |---|---|
        | ğŸ“„ Swagger UI (interactive docs) | [{API_BASE}/api/docs]({API_BASE}/api/docs) |
        | ğŸ“‹ OpenAPI JSON schema | [{API_BASE}/api/openapi.json]({API_BASE}/api/openapi.json) |
        | â¤ï¸ Health check | [{API_BASE}/api/health]({API_BASE}/api/health) |
        | ğŸ“Š Model stats | [{API_BASE}/api/stats]({API_BASE}/api/stats) |
        """)

    # â”€â”€ Swagger UI embedded â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“„ Interactive Swagger UI")
    swagger_html = f"""
    <div style="border-radius:12px; overflow:hidden; border:1px solid #333; box-shadow:0 4px 24px #0008;">
      <iframe src="{API_BASE}/api/docs"
              width="100%" height="650px"
              style="border:none; background:#1a1a2e;"
              title="CyberLens Swagger UI">
      </iframe>
    </div>
    <p style="color:#666; font-size:0.8em; margin-top:6px;">
     â¬† You can try any endpoint directly in the Swagger UI above. Click an endpoint â†’ "Try it out" â†’ "Execute".
    </p>
    """
    components.html(swagger_html, height=700, scrolling=False)

    # â”€â”€ Endpoint Reference â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“š Endpoint Reference")
    ep_cols = st.columns(2)

    with ep_cols[0]:
        st.markdown("""
**Detection Endpoints**
```
POST  /api/detect
```
Analyze a single network connection.  
Returns: `is_threat`, `severity`, `anomaly_score`, `confidence`

```
POST  /api/detect-batch
```
Analyze up to **10,000** connections at once.  
Returns: counts, per-record results

**Health & Info**
```
GET  /api/health   â†’  service status
GET  /api/stats    â†’  model metadata
GET  /             â†’  API overview
```
        """)

    with ep_cols[1]:
        st.markdown("""
**Training Endpoints**
```
POST  /api/train-model   â†’  start training
GET   /api/train-status  â†’  poll progress
POST  /api/train-stop    â†’  stop training
POST  /api/train-reset   â†’  reset state
```

**Authentication:** None (open for local use)  
**Rate limits:** None  
**Max batch size:** 10,000 records  
**Response format:** JSON  
**Base URL:** `http://localhost:8000`
        """)

    # â”€â”€ Live Endpoint Tester â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ§ª Quick Endpoint Tester")
    test_col1, test_col2 = st.columns([1, 1])

    with test_col1:
        endpoint_choice = st.selectbox(
            "Choose endpoint to test",
            ["GET /api/health", "GET /api/stats", "POST /api/detect (sample)"],
            key="api_endpoint_choice"
        )

        if st.button("ğŸš€ Call API", key="call_api_btn"):
            try:
                if endpoint_choice == "GET /api/health":
                    resp = requests.get(f"{API_BASE}/api/health", timeout=5)
                elif endpoint_choice == "GET /api/stats":
                    resp = requests.get(f"{API_BASE}/api/stats", timeout=5)
                else:
                    # Sample normal traffic payload
                    payload = {
                        "duration": 0, "protocol_type": "tcp", "service": "http",
                        "flag": "SF", "src_bytes": 215, "dst_bytes": 45076,
                        "land": 0, "wrong_fragment": 0, "urgent": 0, "hot": 0,
                        "num_failed_logins": 0, "logged_in": 1, "num_compromised": 0,
                        "root_shell": 0, "su_attempted": 0, "num_root": 0,
                        "num_file_creations": 0, "num_shells": 0, "num_access_files": 0,
                        "num_outbound_cmds": 0, "is_host_login": 0, "is_guest_login": 0,
                        "count": 9, "srv_count": 9, "serror_rate": 0.0,
                        "srv_serror_rate": 0.0, "rerror_rate": 0.0, "srv_rerror_rate": 0.0,
                        "same_srv_rate": 1.0, "diff_srv_rate": 0.0, "srv_diff_host_rate": 0.0,
                        "dst_host_count": 9, "dst_host_srv_count": 9,
                        "dst_host_same_srv_rate": 1.0, "dst_host_diff_srv_rate": 0.0,
                        "dst_host_same_src_port_rate": 0.11, "dst_host_srv_diff_host_rate": 0.0,
                        "dst_host_serror_rate": 0.0, "dst_host_srv_serror_rate": 0.0,
                        "dst_host_rerror_rate": 0.0, "dst_host_srv_rerror_rate": 0.0
                    }
                    resp = requests.post(f"{API_BASE}/api/detect", json=payload, timeout=5)

                st.session_state.api_test_response = {
                    "status": resp.status_code,
                    "body": resp.json()
                }
            except Exception as e:
                st.session_state.api_test_response = {"status": "ERROR", "body": str(e)}

    with test_col2:
        result = st.session_state.get("api_test_response")
        if result:
            color = "#00d4aa" if str(result['status']) == "200" else "#ff6b6b"
            st.markdown(f'<span style="color:{color}; font-weight:bold;">HTTP {result["status"]}</span>',
                        unsafe_allow_html=True)
            st.json(result["body"])

    # â”€â”€ Footer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    st.markdown("""
    <div style="text-align: center; color: #666666; padding: 20px;">
        ğŸ” CyberLens - Powered by Explainable AI | 
        Built with Streamlit, FastAPI, SHAP, and Isolation Forest | KDD Cup Dataset
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
